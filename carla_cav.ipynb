{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=carla.Client('localhost',2000)\n",
    "world=client.load_world('Town02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<carla.libcarla.World at 0x17022d4e440>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_lib=world.get_blueprint_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_bp=bp_lib.find(\"vehicle.tesla.model3\")#在蓝图库中找tesla的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "#get_map获取虚拟世界的地图信息，包含拓扑结构、道路网络和建筑物位置\n",
    "#spawn生成点，初始化虚拟世界\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "#随机选择生成点生成车辆\n",
    "# spawn camera\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "#用这个蓝图来创建一个具有 RGB 摄像头传感器的虚拟世界实体\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "#在z=2m的高度处生成了一个摄像头实体\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "#将摄像头附着到了车辆的实体上\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True \n",
    "#同步模式\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "#每隔0.05秒进行一步仿真，每秒20帧图片渲染\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# 生成点对象\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "# 传感器的图片输入到一个image队列之中\n",
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数通常用于计算相机的投影矩阵，\n",
    "#用于将三维世界坐标映射到二维图像坐标，以便进行摄像头校准、3D到2D的投影和其他计算机视觉或计算机图形任务。\n",
    "def build_projection_matrix(w, h, fov):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "    K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的是将三维世界坐标映射到摄像头图像的二维坐标上，用于计算图像中的点\n",
    "def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x)\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return point_img[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "#反转变换矩阵可以用来将虚拟世界中的坐标从相机坐标系转换回世界坐标系。\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()#图片的宽\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()#图片的高\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float()#该属性表示摄像头的视场角（Field of View）\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K = build_projection_matrix(image_w, image_h, fov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box_set = world.get_level_bbs(carla.CityObjectLabel.TrafficLight)\n",
    "bounding_box_set.extend(world.get_level_bbs(carla.CityObjectLabel.TrafficSigns))\n",
    "\n",
    "# Remember the edge pairs\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "    if npc:\n",
    "        npc.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Retrieve and reshape the image\n",
    "    world.tick()\n",
    "    image = image_queue.get()\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "    # Get the camera matrix \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "\n",
    "        # Filter out the ego vehicle\n",
    "        if npc.id != vehicle.id:\n",
    "\n",
    "            bb = npc.bounding_box#非自己车辆，其他的所有实体\n",
    "            dist = npc.get_transform().location.distance(vehicle.get_transform().location)\n",
    "\n",
    "            # Filter for the vehicles within 50m\n",
    "            if dist < 50:\n",
    "\n",
    "            #计算了车辆的前向向量和连接两辆车的向量。\n",
    "            # 如果点积的结果大于1，这表示这两个向量之间的夹角小于90度\n",
    "            #并且它们的方向是大致一致的。在这个上下文中，这意味着另一辆车辆位于摄像头前方，\n",
    "            #车辆的前向方向与连接向量的方向大致一致。因此，通过这个条件判断，代码只会绘制位于摄像头前方的车辆的边界框。\n",
    "                forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "                ray = npc.get_transform().location - vehicle.get_transform().location\n",
    "\n",
    "                if forward_vec.dot(ray) > 1:\n",
    "                    p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "                    verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "                    for edge in edges:\n",
    "                        p1 = get_image_point(verts[edge[0]], K, world_2_camera)\n",
    "                        p2 = get_image_point(verts[edge[1]],  K, world_2_camera)\n",
    "                        cv2.line(img, (int(p1[0]),int(p1[1])), (int(p2[0]),int(p2[1])), (255,0,0, 255), 1)        \n",
    "\n",
    "    cv2.imshow('ImageWindowName',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
